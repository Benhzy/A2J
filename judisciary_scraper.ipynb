{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq #urllib will get the page itself\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import heapq\n",
    "import requests\n",
    "import sys\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import wikipedia\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "therapeutic_justice_type = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://www.judiciary.gov.sg/family'\n",
    "user_agent = {'User-agent' : 'Mozilla/5.0'}\n",
    "page = requests.get(website, headers=user_agent)\n",
    "soup = BeautifulSoup(page.text, 'lxml')\n",
    "fact_cards = soup.find_all('a', {'class': 'nav-link'})\n",
    "tj_dict = {}\n",
    "all_types = []\n",
    "\n",
    "for fact_card in fact_cards[8:]:\n",
    "    tj_type = fact_card.get_text().split('\\n')[1]\n",
    "    tj_desc = fact_card.get_text().split('\\n')[2]\n",
    "    tj_link = fact_card['href']\n",
    "    tj_dict[tj_type] = [tj_desc, tj_link]\n",
    "    all_types.append(tj_type)\n",
    "\n",
    "tj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dict = {}\n",
    "tdesc_dict = {}\n",
    "ndesc_dict = {}\n",
    "ddesc_dict = {}\n",
    "link_dict = {}\n",
    "row_dict = {}\n",
    "nav_link_list = []\n",
    "\n",
    "for type in all_types:\n",
    "    row_link_list = []\n",
    "    with open(type + \".txt\", \"w\") as f:\n",
    "        print(type)\n",
    "        next_page = 'https://www.judiciary.gov.sg' + tj_dict[type][1]\n",
    "        page = requests.get(next_page, headers=user_agent)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        content_desc = soup.find_all('div', {'class': 'sf-content-block'})\n",
    "        accr_desc = soup.find_all('div', {'class': 'accordion-wrapper'})\n",
    "        # This gets everything in a page, including the p and ul tags\n",
    "        for desc in content_desc[2:-6]:\n",
    "            desc_text = desc.get_text()\n",
    "            f.write(desc_text.replace('\\n', ' '))\n",
    "            # print(desc_text.replace('\\n', ' '))\n",
    "            for link in desc.find_all('a'):\n",
    "                desc_dict[link.string] = link['href']\n",
    "\n",
    "        # This gets all the links in the accordion\n",
    "        for desc in accr_desc:\n",
    "            for link in desc.find_all('a'):\n",
    "                link_dict[link.string] = link['href']\n",
    "            \n",
    "        if type ==\"Adoption\" or type == \"Protection for vulnerable adults\" :\n",
    "            timeline_desc = soup.find_all('div', {'class': 'timeline'})\n",
    "            for t_desc in timeline_desc:\n",
    "                timeline_text = t_desc.get_text()\n",
    "                f.write(timeline_text.replace('\\n', ' '))\n",
    "                # print(timeline_text.replace('\\n', ' '))\n",
    "                for link in t_desc.find_all('a'):\n",
    "                    tdesc_dict[link.string] = link['href']\n",
    "\n",
    "        elif type == \"Care and protection for children and young persons\" or type == \"Guardianship\":\n",
    "            nav_desc = soup.find_all('li', {'class': 'nav-item w-100'})\n",
    "            for n_desc in nav_desc:\n",
    "                # print(n_desc)\n",
    "                nav_text = n_desc.get_text()\n",
    "                f.write(nav_text.replace('\\n', ' '))\n",
    "                # print(nav_text.replace('\\n', ' '))\n",
    "                for link in n_desc.find_all('a'):\n",
    "                    nav_link_list.append(link['href'])\n",
    "\n",
    "        else:\n",
    "            div_desc = soup.find_all('div', {'class': 'row'})\n",
    "            if type != \"Direct judicial communication for international family proceedings affecting children\" and type != \"Syariah Court orders\":\n",
    "                type_list = []\n",
    "                for d_desc in div_desc[:-2]:\n",
    "                    div_text = d_desc.get_text()\n",
    "                    f.write(div_text.replace('\\n', ' '))\n",
    "                    # print(div_text.replace('\\n', ' '))\n",
    "                    type_list.append(list(filter(None,div_text.split(\"\\n\"))))\n",
    "                    for link in d_desc.find_all('a'):\n",
    "                        row_link_list.append(link['href'])\n",
    "                    row_dict[type] = row_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt(txt_name, link):\n",
    "    with open(txt_name, \"a\") as f:\n",
    "        next_page = 'https://www.judiciary.gov.sg' + link\n",
    "        page = requests.get(next_page, headers=user_agent)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        content_desc = soup.find_all('div', {'class': 'sf-content-block'})\n",
    "        for desc in content_desc[2:-6]:\n",
    "            desc_text = desc.get_text()\n",
    "            f.write(desc_text)\n",
    "            # for link in desc.find_all('a'):\n",
    "            #     desc_dict[link.string] = link['href']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Adoption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adoption_int_links = dict(itertools.islice(tdesc_dict.items(), 4))\n",
    "for link in adoption_int_links.values():\n",
    "    get_txt('adoption_internal.txt', link)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Protection for vulnerable adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protection_vulnerable_int_links =  dict(itertools.islice(tdesc_dict.items(), len(tdesc_dict)-2, None))\n",
    "for link in protection_vulnerable_int_links.values():\n",
    "    get_txt('protection_vulnerable_internal.txt', link)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Care and protection for children and young persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in nav_link_list[:2]:\n",
    "    get_txt('care_protection_children_internal.txt', link)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardianship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in nav_link_list[2:]:\n",
    "    get_txt('guardianship_internal.txt', link)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divorce, Deputyship, Family justice courts appeals, Family guidance for children and young persons, International child abduction, Probate and administration, Protection against family violence, Maintenance, Mediation and counselling in the family justice courts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the dictionary and get the key and value\n",
    "for key, list_of_links in row_dict.items():\n",
    "    key = key.replace(\" \", \"_\").lower()\n",
    "    for link in list_of_links:\n",
    "        get_txt(key + '_internal.txt', link)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Civil Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://www.judiciary.gov.sg/civil'\n",
    "user_agent = {'User-agent' : 'Mozilla/5.0'}\n",
    "page = requests.get(website, headers=user_agent)\n",
    "soup = BeautifulSoup(page.text, 'lxml')\n",
    "fact_cards = soup.find_all('a', {'class': 'nav-link'})\n",
    "tj_dict = {}\n",
    "all_types = []\n",
    "\n",
    "for fact_card in fact_cards[8:]:\n",
    "    tj_type = fact_card.get_text().split('\\n')[1]\n",
    "    tj_desc = fact_card.get_text().split('\\n')[2]\n",
    "    tj_link = fact_card['href']\n",
    "    tj_dict[tj_type] = [tj_desc, tj_link]\n",
    "    all_types.append(tj_type)\n",
    "\n",
    "tj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dict = {}\n",
    "tdesc_dict = {}\n",
    "ndesc_dict = {}\n",
    "ddesc_dict = {}\n",
    "link_dict = {}\n",
    "row_dict = {}\n",
    "nav_link_list = []\n",
    "\n",
    "for type in all_types:\n",
    "    row_link_list = []\n",
    "    with open(os.path.join('civil_db', type + \".txt\"), \"w\") as f:\n",
    "        print(type)\n",
    "        next_page = 'https://www.judiciary.gov.sg' + tj_dict[type][1]\n",
    "        page = requests.get(next_page, headers=user_agent)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        content_desc = soup.find_all('div', {'class': 'sf-content-block'})\n",
    "        accr_desc = soup.find_all('div', {'class': 'accordion-wrapper'})\n",
    "        # This gets everything in a page, including the p and ul tags\n",
    "        for desc in content_desc[2:6]:\n",
    "            desc_text = desc.get_text()\n",
    "            f.write(desc_text.replace('\\n', ' '))\n",
    "            print(desc_text.replace('\\n', ' '))\n",
    "            for link in desc.find_all('a'):\n",
    "                desc_dict[link.string] = link['href']\n",
    "\n",
    "            div_desc = soup.find_all('div', {'class': 'row'})\n",
    "            if type == \"Civil claims (from 1 April 2022)\" or type == \"Bankruptcy\" or type == \"Community and neighbour disputes\" or type == \"Employment claims\" or type == \"Protection from harassment\" or type == \"Small claims\":\n",
    "                type_list = []\n",
    "                for d_desc in div_desc[:-2]:\n",
    "                    div_text = d_desc.get_text()\n",
    "                    f.write(div_text.replace('\\n', ' '))\n",
    "                    # print(div_text.replace('\\n', ' '))\n",
    "                    type_list.append(list(filter(None,div_text.split(\"\\n\"))))\n",
    "                    for link in d_desc.find_all('a'):\n",
    "                        row_link_list.append(link['href'])\n",
    "                    row_dict[type] = row_link_list        \n",
    "            \n",
    "\n",
    "        # This gets all the links in the accordion\n",
    "        for desc in accr_desc:\n",
    "            for link in desc.find_all('a'):\n",
    "                link_dict[link.string] = link['href']\n",
    "        print('-------------------------------------------------------')\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt(type, link):\n",
    "    with open(os.path.join('civil_db', type + \".txt\"), \"a\") as f:\n",
    "        next_page = 'https://www.judiciary.gov.sg' + link\n",
    "        page = requests.get(next_page, headers=user_agent)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        content_desc = soup.find_all('div', {'class': 'sf-content-block'})\n",
    "        for desc in content_desc[2:-6]:\n",
    "            desc_text = desc.get_text()\n",
    "            f.write(desc_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Civil claims (from 1 April 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in row_dict.items():\n",
    "    for link in value:\n",
    "        get_txt(key+\"_internal\", link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "747d2ce94befc444b26ce8ac4106bd565fa9a7adb29f4c71228a18318693a3de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
